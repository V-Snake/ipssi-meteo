from datetime import datetime, timedelta
from airflow import DAG
from airflow.operators.bash import BashOperator
from airflow.operators.python import PythonOperator
from airflow.providers.http.operators.http import SimpleHttpOperator
import requests
import json

# Configuration par dÃ©faut
default_args = {
    'owner': 'airflow',
    'depends_on_past': False,
    'start_date': datetime(2023, 1, 1),
    'email_on_failure': False,
    'email_on_retry': False,
    'retries': 1,
    'retry_delay': timedelta(minutes=2),
}

# DAG pour les contrÃ´les du dashboard
with DAG(
    'dashboard_control_center',
    default_args=default_args,
    description='Centre de contrÃ´le pour les dashboards Grafana',
    schedule_interval='*/5 * * * *',  # Toutes les 5 minutes
    catchup=False,
    tags=['dashboard', 'control', 'grafana', 'realtime'],
) as dag:

    # 1. VÃ©rification de l'Ã©tat des services
    def check_services_status():
        """VÃ©rifie l'Ã©tat de tous les services du pipeline"""
        services = {
            'kafka': {'url': 'http://kafka:9092', 'status': 'unknown'},
            'namenode': {'url': 'http://namenode:9870/webhdfs/v1/?op=LISTSTATUS', 'status': 'unknown'},
            'analytics_api': {'url': 'http://analytics-api:8000/health', 'status': 'unknown'},
            'grafana': {'url': 'http://grafana:3000/api/health', 'status': 'unknown'},
            'clickhouse': {'url': 'http://clickhouse:8123/ping', 'status': 'unknown'}
        }
        
        for service, config in services.items():
            try:
                if service == 'kafka':
                    # Kafka n'a pas d'endpoint HTTP, on vÃ©rifie juste la connectivitÃ©
                    response = requests.get(config['url'], timeout=2)
                else:
                    response = requests.get(config['url'], timeout=5)
                
                config['status'] = 'healthy' if response.status_code in [200, 404] else 'unhealthy'
                print(f"âœ… {service}: {config['status']}")
            except Exception as e:
                config['status'] = 'unhealthy'
                print(f"âŒ {service}: {config['status']} - {str(e)}")
        
        return services

    check_services = PythonOperator(
        task_id='check_services_status',
        python_callable=check_services_status,
    )

    # 2. GÃ©nÃ©ration de mÃ©triques pour Grafana
    def generate_metrics():
        """GÃ©nÃ¨re des mÃ©triques simulÃ©es pour les dashboards"""
        print("ðŸ“Š GÃ©nÃ©ration des mÃ©triques pour Grafana...")
        
        # Simulation de mÃ©triques mÃ©tÃ©o
        import random
        from datetime import datetime
        
        cities = ['London', 'Paris', 'New York']
        metrics = []
        
        for city in cities:
            temp = round(random.uniform(15, 30), 1)
            humidity = round(random.uniform(40, 80), 1)
            pressure = round(random.uniform(1000, 1020), 1)
            
            metrics.append({
                'city': city,
                'temperature': temp,
                'humidity': humidity,
                'pressure': pressure,
                'timestamp': datetime.now().isoformat()
            })
        
        print(f"âœ… MÃ©triques gÃ©nÃ©rÃ©es pour {len(cities)} villes")
        return metrics

    generate_metrics_task = PythonOperator(
        task_id='generate_metrics',
        python_callable=generate_metrics,
    )

    # 3. Mise Ã  jour des dashboards Grafana
    def update_grafana_dashboards():
        """Met Ã  jour les dashboards Grafana avec de nouvelles donnÃ©es"""
        print("ðŸ”„ Mise Ã  jour des dashboards Grafana...")
        
        # Simulation de la mise Ã  jour des dashboards
        dashboards = [
            "Weather Pipeline - Temps RÃ©el",
            "Pipeline Control Center",
            "Lambda Architecture Overview"
        ]
        
        for dashboard in dashboards:
            print(f"  - Mise Ã  jour: {dashboard}")
            # Ici on pourrait faire des appels API Ã  Grafana pour mettre Ã  jour les dashboards
        
        print("âœ… Dashboards mis Ã  jour")
        return "Dashboards updated"

    update_dashboards = PythonOperator(
        task_id='update_grafana_dashboards',
        python_callable=update_grafana_dashboards,
    )

    # 4. Test des contrÃ´les du dashboard
    def test_dashboard_controls():
        """Teste les contrÃ´les du dashboard"""
        print("ðŸ§ª Test des contrÃ´les du dashboard...")
        
        controls = [
            "Bouton DÃ©marrer Pipeline",
            "Bouton ArrÃªter Pipeline", 
            "Bouton RedÃ©marrer Pipeline",
            "Bouton Actualiser DonnÃ©es",
            "ContrÃ´les Speed Layer",
            "ContrÃ´les Batch Layer",
            "ContrÃ´les Serving Layer",
            "ArrÃªt d'urgence"
        ]
        
        for control in controls:
            print(f"  - Test: {control} âœ…")
        
        print("âœ… Tous les contrÃ´les testÃ©s")
        return "Controls tested"

    test_controls = PythonOperator(
        task_id='test_dashboard_controls',
        python_callable=test_dashboard_controls,
    )

    # 5. Notification de statut
    def send_status_notification():
        """Envoie une notification de statut du pipeline"""
        print("ðŸ“¢ Envoi de notification de statut...")
        
        status = {
            'timestamp': datetime.now().isoformat(),
            'pipeline_status': 'running',
            'services': {
                'kafka': 'healthy',
                'hdfs': 'healthy', 
                'analytics': 'healthy',
                'grafana': 'healthy'
            },
            'dashboards': 'updated',
            'controls': 'tested'
        }
        
        print(f"âœ… Notification envoyÃ©e: {status}")
        return status

    send_notification = PythonOperator(
        task_id='send_status_notification',
        python_callable=send_status_notification,
    )

    # DÃ©finition des dÃ©pendances
    check_services >> generate_metrics_task >> update_dashboards >> test_controls >> send_notification
